{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.9.0)\n",
      "Collecting groq\n",
      "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from groq) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\n",
      "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
      "Installing collected packages: groq\n",
      "  Attempting uninstall: groq\n",
      "    Found existing installation: groq 0.9.0\n",
      "    Uninstalling groq-0.9.0:\n",
      "      Successfully uninstalled groq-0.9.0\n",
      "Successfully installed groq-0.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~upyterlab (C:\\Users\\musta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~upyterlab (C:\\Users\\musta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~upyterlab (C:\\Users\\musta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mem0ai 0.0.5 requires groq<0.10.0,>=0.9.0, but you have groq 0.11.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "! pip install -U groq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GROQ_API_KEY'] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# client initiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test groq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Explain the importance of fast language models\"}\n",
    "    ],\n",
    "    model=\"llama3-70b-8192\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in today's natural language processing (NLP) landscape, and their importance can be attributed to several factors:\n",
      "\n",
      "1. **Real-time Applications**: Fast language models enable real-time applications such as chatbots, virtual assistants, and language translation systems to respond quickly and efficiently. This is particularly important in scenarios where timely responses are critical, such as customer support or emergency services.\n",
      "2. **Low-Latency Inference**: Fast language models can perform inference (i.e., generate text or make predictions) rapidly, which is essential for applications that require immediate responses. This low-latency inference capability is critical in applications like language translation, sentiment analysis, and text summarization.\n",
      "3. **Scalability**: Fast language models can handle large volumes of data and scale to meet the demands of high-traffic applications. This scalability is vital for applications like social media, online forums, and customer review platforms, where large amounts of text data need to be processed quickly.\n",
      "4. **Energy Efficiency**: Fast language models can reduce energy consumption and carbon footprint, making them more environmentally friendly. This is particularly important for large-scale NLP applications that require significant computational resources.\n",
      "5. **Improved User Experience**: Fast language models can provide a seamless and responsive user experience, leading to increased user satisfaction and engagement. This is critical for applications like language translation, where slow response times can lead to frustration and abandonment.\n",
      "6. **Competitive Advantage**: Fast language models can provide a competitive advantage in industries like customer service, marketing, and healthcare, where timely and accurate language processing can be a key differentiator.\n",
      "7. **Research and Development**: Fast language models can accelerate research and development in NLP, enabling researchers to experiment and iterate more quickly, leading to faster breakthroughs and advancements in the field.\n",
      "8. **Edge Computing**: Fast language models can be deployed on edge devices, such as smartphones, smart home devices, or autonomous vehicles, enabling real-time language processing and reducing latency.\n",
      "9. **Cost Savings**: Fast language models can reduce computational costs and infrastructure requirements, leading to significant cost savings for organizations and businesses.\n",
      "10. **Enhanced Security**: Fast language models can help detect and respond to security threats, such as spam, phishing, and malware, more quickly and effectively, enhancing overall security posture.\n",
      "\n",
      "In summary, fast language models are essential for building responsive, scalable, and efficient NLP applications that can provide a competitive advantage, improve user experience, and drive innovation in various industries.\n"
     ]
    }
   ],
   "source": [
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
